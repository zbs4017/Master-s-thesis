\chapter{绪\hspace{6pt}论}

随着硬件技术的快速发展，以RDMA分离式内存、持久性内存和CXL为代表的新型技术为优化内存资源利用率提供了全新思路。这些技术能够支持将访问频率较低的冷数据迁移至低成本存储设备，并按实际需求动态换入内存，有效缓解了内存容量压力。然而，现有研究主要关注通过应用程序接口(API)实现冷数据迁移的显式管理达到最优性能，这导致未经专门优化的传统应用程序难以直接从中受益。基于Linux内核缺页中断机制的透明冷数据卸载技术为解决这一问题提供了新的途径。这种方案无需修改应用程序即可自动实现冷热数据的识别与管理，但现有研究较少涉及如何在异构存储后端环境下准确估算工作集这一关键问题。本研究致力于填补这一研究空白，通过探索面向异构存储后端的高效工作集估计算法以及冷热页面识别算法，以期在容器化环境下显著提升内存资源利用效率，实现内存成本的优化。

\section{研究工作的背景与意义}

近年来，内存技术发展与应用需求之间的矛盾日益凸显。在技术层面，DRAM制造工艺正面临严峻挑战。如Onur Mutlu\citing{mutlu2013memory}所指出，随着工艺节点向10nm及以下推进，DRAM存储单元的微缩已接近物理极限，位密度提升显著放缓。为维持性能增长，业界不得不采用多重曝光（Multiple Patterning）和极紫外光刻（EUV Lithography）等复杂工艺，导致制造成本大幅上升。Patel等人\citing{patel2023xfm}的研究表明，当前内存成本已占据数据中心总运营成本的50\%以上，制约了数据中心的发展。同时，DRAM的刷新功耗随容量增长持续攀升，进一步加剧了能源消耗问题。

与DRAM技术发展受限形成鲜明对比的是，现代互联网应用、容器技术以及大数据分析、人工智能等新兴领域的数据密集度急剧增加，对内存容量、带宽、延迟和吞吐量提出了前所未有的高要求。这种供需失衡使得内存资源的高效利用变得尤为重要。

然而，实际生产环境中的内存利用状况却不容乐观。Reiss等人\citing{reiss2012heterogeneity}对大规模生产集群的统计分析显示，在70\%的运行时间内，集群平均有30\%的内存处于闲置状态；而在已分配的内存中，实际使用率仅为50\%。这种"高成本，低利用"的现象主要由以下因素导致：首先，现代数据中心需要同时支持在线服务、批处理任务、数据分析等多种类型的工作负载，其资源需求和运行时长存在显著差异，导致资源分配难以优化；其次，为保证服务质量（Service Level Objective， SLO），系统通常需要按照峰值需求预留内存资源，造成非高峰期的资源闲置；最后，负载的周期性特征（如日间与夜间的访问量差异）以及任务执行的固有特性（如JVM运行时环境的内存开销）进一步加剧了内存利用率低下的问题。

新型存储和互联技术的快速发展为解决内存系统面临的挑战提供了多种的解决方案。NVMe SSD、持久性内存（Persistent Memory， PMem）等新型存储设备显著降低了存储访问延迟，而基于RDMA的高速网络技术实现了高效的远程内存访问。同时，基于软件的内存压缩技术的成熟为提升内存密度提供了新的技术路径，这些进步为构建异构分层内存系统（Heterogeneous Memory Hierarchy）奠定了技术基础。具体而言，RDMA技术凭借其微秒级的访问延迟和零拷贝特性，使得远程内存访问成为可能；持久性内存则因其接近DRAM的访问速度和字节寻址能力，成为理想的冷数据存储介质。此外，内存压缩技术通过对内存数据进行实时压缩和解压缩，在保证访问性能的同时显著提升了内存的有效容量。

基于上述技术进展，通过将冷数据迁移至低成本存储设备，构建异构分层内存系统，理论上可以在保证应用性能的同时显著降低总体拥有成本（Total Cost of Ownership， TCO）。在早期计算机系统中，由于磁盘的访问延迟过高，频繁的内存换入换出操作会导致系统性能的急剧下降，因此该策略并未得到广泛应用。然而，随着新型存储和互联技术的成熟，这一方案重新成为可能。

在容器化部署环境下，通过准确估算并实时监控容器中应用负载的活跃工作集大小，并结合Linux内核的内存回收机制，主动地将冷内存页透明地卸载至异构存储设备，有望在保障服务质量（Quality of Service， QoS）的前提下，显著提升单台物理服务器可承载的容器数量，从而进一步提高数据中心的资源利用率和经济效益。这一研究不仅具有重要的理论价值，也为解决当前内存资源利用效率低下的实际问题提供了可行的技术路径。

\section{国内外研究历史与现状}

\subsection{分层内存研究历史与现状}

虚拟内存技术的早期发展源于应对主存容量不足的挑战。程序运行所需的内存空间往往超过实际可用物理内存，虚拟内存通过将不常用的程序段（页面）迁移至辅助存储设备（如磁盘）来模拟更大的内存空间，这一机制有效解决了内存容量限制问题\citing{10.1145/356571.356573}。Unix系统引入的分页机制最初旨在优化内存管理效率，减少外部碎片。通过将内存划分为固定大小的页面，系统能够更灵活地进行内存分配与回收。随后，这一机制被扩展以支持虚拟内存功能，实现了页面的动态换入换出，从而形成了分层内存架构的雏形\citing{10.1145/1476793.1476834,6770405}。

尽管存储技术持续进步，但磁盘和SSD的访问速度仍显著低于主存。频繁的页面交换操作（thrashing）会导致系统性能显著下降。因此，优化内存管理以减少页面交换、提高主存利用率成为这一阶段的研究重点\citing{Denning1968ThrashingIC}。随着硬件设备的不断发展，分层内存技术获得了新的发展机遇。不同存储介质在延迟和带宽方面的差异，使得存储层次结构更加丰富和完善。

非易失性内存（NVM）的出现标志着内存技术的重要突破。NVM不仅具备TB级的存储容量，还拥有接近DRAM的访问延迟，使其成为存储冷数据的理想介质，为分层内存架构提供了新的可能性。学术界针对这一硬件特性开展了广泛研究。

Qureshi等人\citing{10.1145/1555754.1555760}提出使用相变存储器（PCM）作为主存，DRAM作为透明缓存的架构，类似于CPU的L3缓存，由硬件自动决定数据存放和替换策略。然而，这种硬件方法缺乏灵活性，难以针对不同应用场景进行优化，频繁的页面调度还可能导致功耗增加和设备寿命缩短。

Wang等人\citing{wang2024nvpc}开发了NVPC，一种利用NVM增强页面缓存来加速现有内核文件系统的透明加速器。NVPC包含两个主要优化：同步写入加速和缓存未命中优化。对于同步写入，NVPC采用高性能的日志结构将数据从慢速磁盘重定向到快速NVM，并利用NVM的字节可寻址特性减少写入放大。对于缓存未命中，NVPC利用NVM上的空闲空间扩展DRAM页面缓存，从而容纳更多更大的工作负载。NVPC完全作为页面缓存实现，为磁盘文件系统提供高效加速，同时对用户完全透明，并与底层文件系统完全兼容。该调度算法对同步写操作繁重的应用提升效果最为显著。

Fedorov等人\citing{10.1145/3132402.3132409}提出了一种基于Linux的交换页面管理和swap机制，充分考虑了NVM的低延迟、高并行性和优异的随机访问性能。该研究采用了更智能、更激进的预取策略，并对操作系统内核的多个方面进行了修改。这种方法在运行内存需求量大的应用程序时，能够在降低内存成本的同时，将性能保持在与纯DRAM系统相当的水平。

上述方法均通过透明卸载的方式将冷数据迁移到NVM，使得现有程序无需修改即可获得性能提升。此外，还有研究通过使用NVM提供的编程接口（如英特尔开发的PMDK）来充分利用NVM特性，这类方法主要应用于存储领域。

DeBrabant等人\citing{DeBrabant2014APO}研究了NVM对在线事务处理（OLTP）数据库管理系统（DBMS）架构的影响。研究者通过硬件仿真器模拟了NVM-only和NVM+DRAM两种存储架构，并使用YCSB和TPC-C基准测试，发现现有DBMS无法充分利用NVM技术，因为其内部架构基于内存易失性的假设。因此，需要针对NVM特性重新设计数据库系统。

Lindstrom等人\citing{7304362}、van Renen等人\citing{10.1145/3183713.3196897}、喻明\citing{喻明2023面向NVM和SSD的列存数据库存储引擎设计与实现}、董创轼\citing{董创轼2023基于NVM的数据库存储引擎优化技术研究}以及李心池\citing{李心池2018基于NVM的内存数据库多表连接操作的设计与优化}等研究均致力于利用NVM优化数据库性能，并取得了不同程度的性能提升。

基于RDMA的远程内存技术通过解决不同节点间内存负载不均衡的问题，实现了内存利用率的提升。Gu等人\citing{201565}提出的Infiniswap系统利用Infiniband的RDMA低延迟特性，将多个节点的远程内存作为交换空间，并将其划分为固定大小的slab进行分布式管理。通过RDMA操作实现低延迟的同步远程写入和高容错的异步磁盘写入，同时利用分布式的Infiniswap守护进程，无需中央协调即可协同管理这些远程可访问的内存，并主动监控、预分配和驱逐slab。与磁盘相比，应用程序吞吐量提高了4倍至15.4倍。

Amaro等人\citing{10.1145/3342195.3387522}进一步提出了FastSwap和远端内存感知集群调度器。FastSwap直接与Linux中的cgroup交互，强制执行本地内存与远端内存的交互。远端内存感知集群调度器通过感知集群中的远端内存，减少某些现有作业使用的本地内存，并使用远端内存来确保所有作业都有足够的总内存。这种方法比Infiniswap更加有效。

上述方法均采用透明卸载策略，通过在内核中修改swap逻辑，使得应用层无需进行任何更改即可获得性能提升。

压缩内存技术也可作为一种冷内存存储方案，尽管其实现完全依赖软件。该技术通过压缩内存数据来减少内存占用，并在需要时进行解压，其性能主要取决于压缩比。谷歌\citing{10.1145/3297858.3304053}自2019年起就开始使用压缩内存作为交换后端，通过更好地识别冷热页面和工作集大小来提高内存利用率。


\subsection{工作集估计算法研究历史与现状}

Linux中工作集大小(Working Set Size,WSS)是指一个进程在特定时间窗口内实际需要并频繁使用的那部分内存容量​。其核心原理基于页表的“引用（Referenced）”标志：一旦 CPU 访问了某页面，该标志即被置位；统计被置位的页面数目即能估算进程在该时间段内的活跃内存使用量。

Vlad Nitu等人\citing{10.1145/3179422,10.1145/1165389.945462}通过在Guest OS中加载一个伪设备驱动（气球驱动）来回收内存，Guest OS根据自身内存管理策略，决定回收哪些页面，甚至将它们交换到虚拟磁盘。他采用了一种统计采样的方法来估计每个虚拟机的工作集大小，首先使选定页面的所有相关映射无效，下一次Guest OS访问这些页面时，会触发一个陷阱（trap），重新建立映射，增加一个“已访问”页面计数器，在采样周期结束时，用“已访问”页面数量（t）除以采样页面总数（n），得到活跃内存比例的统计估计值。

Anna Melekhova等人\citing{Melekhova2015EstimatingWS}针对虚拟化中的气球模型做了增强，他们在Guest OS中使用VirtIO balloon驱动程序来获取内部计数器值，然后传递到hypervisor中，并使用这些计数器值来估算工作集大小，然后在通过hypervisor接口向VirtIO balloon驱动程序发送命令来释放或压缩页面。

\section{本文的主要贡献与创新}


\section{本论文的结构安排}
本文的章节结构安排如下：

\footnote{脚注序号“\ding{172}，……，\ding{180}”的字体是“正文”，不是“上标”，序号与脚注内容文字之间空1个半角字符，脚注的段落格式为：单倍行距，段前空0磅，段后空0磅，悬挂缩进1.5字符；中文用宋体，字号为小五号，英文和数字用Times New Roman字体，字号为9磅；中英文混排时，所有标点符号（例如逗号“，”、括号“（）”等）一律使用中文输入状态下的标点符号，但小数点采用英文状态下的样式“.”。}