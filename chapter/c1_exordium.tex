\chapter{绪\hspace{6pt}论}

随着硬件技术的快速发展，以RDMA分离式内存、持久性内存和CXL为代表的新型技术为优化内存资源利用率提供了全新思路。这些技术能够支持将访问频率较低的冷数据迁移至低成本存储设备，并按实际需求动态换入内存，有效缓解了内存容量压力。然而，现有研究主要关注通过应用程序接口(API)实现冷数据迁移的显式管理达到最优性能，这导致未经专门优化的传统应用程序难以直接从中受益。基于Linux内核缺页中断机制的透明冷数据卸载技术为解决这一问题提供了新的途径。这种方案无需修改应用程序即可自动实现冷热数据的识别与管理，但现有研究较少涉及如何在异构存储后端环境下准确估算工作集这一关键问题。本研究致力于填补这一研究空白，通过探索面向异构存储后端的高效工作集估计算法以及冷热页面识别算法，以期在容器化环境下显著提升内存资源利用效率，实现内存成本的优化。

\section{研究工作的背景与意义}

随着信息技术的迅猛发展，传统DRAM技术与新兴应用需求之间的矛盾日益突出。在工艺技术层面，DRAM面临着严峻的物理局限性挑战。Mutlu\citing{mutlu2013memory}指出，当制程工艺迈向10nm及更先进节点时，DRAM存储单元的微缩已逼近物理极限，位密度提升速率显著降低。为维持性能增长趋势，产业界不得不采用多重曝光和极紫外光刻等高复杂度制造工艺，这导致了单位存储容量的制造成本呈指数级上升。根据Patel等人\citing{patel2023xfm}的实证研究，内存系统支出已占据现代数据中心总运营成本的50\%以上，成为制约大规模计算设施扩展的关键瓶颈。此外，DRAM的周期性刷新操作所需能耗随存储容量的增长而显著攀升，这进一步加剧了计算系统的能源效率问题。

与DRAM技术发展面临瓶颈形成鲜明对比的是，现代计算范式对内存系统提出了更为严苛的需求。云计算、容器虚拟化、大规模数据分析以及深度学习等新兴计算模式呈现出显著的数据密集特征，它们对内存系统的容量、带宽、访问延迟和吞吐量等核心性能指标提出了前所未有的挑战。特别是在互联网应用规模持续扩张的背景下，数据规模呈指数级增长，这种供给能力与需求规模之间的失衡使得内存资源的高效管理与优化变得愈发重要。

然而，实际生产环境中的内存利用状况却不容乐观。Reiss等人\citing{reiss2012heterogeneity}对大规模生产集群的统计分析显示，在70\%的运行时间内，集群平均有30\%的内存处于闲置状态；而在已分配的内存中，实际使用率仅为50\%。这种"高成本，低利用"的现象主要由以下因素导致：首先，现代数据中心需要同时支持在线服务、批处理任务、数据分析等多种类型的工作负载，其资源需求和运行时长存在显著差异，导致资源分配难以优化；其次，为保证服务质量（Service Level Objective,SLO），系统通常需要按照峰值需求预留内存资源，造成非高峰期的资源闲置；最后，负载的周期性特征（如日间与夜间的访问量差异）以及任务执行的固有特性（如JVM运行时环境的内存开销）进一步加剧了内存利用率低下的问题。

新型存储和互联技术的快速发展为解决内存系统面临的挑战提供了多种的解决方案。NVMe SSD、NVM等新型存储设备显著降低了存储访问延迟，而基于RDMA的高速网络技术实现了高效的远程内存访问。同时，基于软件的内存压缩技术的成熟为提升内存密度提供了新的技术路径，这些进步为构建异构分层内存系统奠定了技术基础。具体而言，RDMA技术凭借其微秒级的访问延迟和零拷贝特性，使得远程内存访问成为可能；持久性内存则因其接近DRAM的访问速度和字节寻址能力，成为理想的冷数据存储介质。此外，内存压缩技术通过对内存数据进行实时压缩和解压缩，在保证访问性能的同时显著提升了内存的有效容量。

基于上述技术进展，通过将冷数据迁移至低成本存储设备，构建异构分层内存系统，理论上可以在保证应用性能的同时显著降低总体拥有成本（Total Cost of Ownership， TCO）。在早期计算机系统中，由于磁盘的访问延迟过高，频繁的内存换入换出操作会导致系统性能的急剧下降，因此该策略并未得到广泛应用。然而，随着新型存储和互联技术的成熟，这一方案重新成为可能。

在容器化部署环境下，通过准确估算并实时监控容器中应用负载的活跃工作集大小，并结合Linux内核的内存回收机制，主动地将冷内存页透明地卸载至异构存储设备，有望在保障服务质量（Quality of Service,QoS）的前提下，显著提升单台物理服务器可承载的容器数量，从而进一步提高数据中心的资源利用率和经济效益。这一研究不仅具有重要的理论价值，也为解决当前内存资源利用效率低下的实际问题提供了可行的技术路径。

\section{国内外研究历史与现状}

\subsection{分层内存研究历史与现状}

虚拟内存技术的早期发展源于应对主存容量不足的挑战。程序运行所需的内存空间往往超过实际可用物理内存，虚拟内存通过将不常用的程序段（页面）迁移至辅助存储设备（如磁盘）来模拟更大的内存空间，这一机制有效解决了内存容量限制问题\citing{10.1145/356571.356573}。Unix系统引入的分页机制最初旨在优化内存管理效率，减少外部碎片。通过将内存划分为固定大小的页面，系统能够更灵活地进行内存分配与回收。随后，这一机制被扩展以支持虚拟内存功能，实现了页面的动态换入换出，从而形成了分层内存架构的雏形\citing{10.1145/1476793.1476834,6770405}。

尽管存储技术持续进步，但磁盘和SSD的访问速度仍显著低于主存。频繁的页面交换操作（thrashing）会导致系统性能显著下降。因此，优化内存管理以减少页面交换、提高主存利用率成为这一阶段的研究重点\citing{Denning1968ThrashingIC}。随着硬件设备的不断发展，分层内存技术获得了新的发展机遇。不同存储介质在延迟和带宽方面的差异，使得存储层次结构更加丰富和完善。

非易失性内存（NVM）的出现标志着内存技术的重要突破。NVM不仅具备TB级的存储容量，还拥有接近DRAM的访问延迟，使其成为存储冷数据的理想介质，为分层内存架构提供了新的可能性。学术界针对这一硬件特性开展了广泛研究。

Qureshi等人\citing{10.1145/1555754.1555760}提出使用相变存储器（PCM）作为主存，DRAM作为透明缓存的架构，类似于CPU的L3缓存，由硬件自动决定数据存放和替换策略。然而，这种硬件方法缺乏灵活性，难以针对不同应用场景进行优化，频繁的页面调度还可能导致功耗增加和设备寿命缩短。

Wang等人\citing{wang2024nvpc}开发了NVPC，一种利用NVM增强页面缓存来加速现有内核文件系统的透明加速器。NVPC包含两个主要优化：同步写入加速和缓存未命中优化。对于同步写入，NVPC采用高性能的日志结构将数据从慢速磁盘重定向到快速NVM，并利用NVM的字节可寻址特性减少写入放大。对于缓存未命中，NVPC利用NVM上的空闲空间扩展DRAM页面缓存，从而容纳更多更大的工作负载。NVPC完全作为页面缓存实现，为磁盘文件系统提供高效加速，同时对用户完全透明，并与底层文件系统完全兼容。该调度算法对同步写操作繁重的应用提升效果最为显著。

Fedorov等人\citing{10.1145/3132402.3132409}提出了一种基于Linux的交换页面管理和swap机制，充分考虑了NVM的低延迟、高并行性和优异的随机访问性能。该研究采用了更智能、更激进的预取策略，并对操作系统内核的多个方面进行了修改。这种方法在运行内存需求量大的应用程序时，能够在降低内存成本的同时，将性能保持在与纯DRAM系统相当的水平。

上述方法均通过透明卸载的方式将冷数据迁移到NVM，使得现有程序无需修改即可获得性能提升。除了上述基于透明卸载的方案外，另一类研究致力于通过NVM专用编程接口（如英特尔开发的PMDK）充分发挥NVM特性，这些工作主要集中在存储系统优化领域。

DeBrabant等人\citing{DeBrabant2014APO}研究了NVM对在线事务处理（OLTP）数据库管理系统（DBMS）架构的影响。研究者通过硬件仿真器模拟了NVM-only和NVM+DRAM两种存储架构，并使用YCSB和TPC-C基准测试，发现现有DBMS无法充分利用NVM技术，因为其内部架构基于内存易失性的假设。因此，需要针对NVM特性重新设计数据库系统。

Lindstrom等人\citing{7304362}、van Renen等人\citing{10.1145/3183713.3196897}、喻明\citing{喻明2023面向NVM和SSD的列存数据库存储引擎设计与实现}、董创轼\citing{董创轼2023基于NVM的数据库存储引擎优化技术研究}以及李心池\citing{李心池2018基于NVM的内存数据库多表连接操作的设计与优化}等研究均致力于利用NVM优化数据库性能，并取得了不同程度的性能提升。

基于RDMA的远程内存技术通过解决不同节点间内存负载不均衡的问题，实现了内存利用率的提升。Gu等人\citing{201565}提出的Infiniswap系统利用Infiniband的RDMA低延迟特性，将多个节点的远程内存作为交换空间，并将其划分为固定大小的slab进行分布式管理。通过RDMA操作实现低延迟的同步远程写入和高容错的异步磁盘写入，同时利用分布式的Infiniswap守护进程，无需中央协调即可协同管理这些远程可访问的内存，并主动监控、预分配和驱逐slab。与磁盘相比，应用程序吞吐量提高了4倍至15.4倍。

Amaro等人\citing{10.1145/3342195.3387522}提出的FastSwap系统进一步优化了基于RDMA的远端内存架构。该系统通过直接与Linux的cgroup子系统交互，实现了本地内存与远端内存之间的细粒度管理。其创新之处在于引入了远端内存感知集群调度器，该调度器能够全局感知集群中的远端内存资源分布，并据此动态调整各作业的本地内存配额，确保资源利用的均衡性。实验表明，相比Infiniswap，FastSwap在资源利用效率和系统吞吐量方面均取得了显著提升。

随着硬件加速发展和软件算法的优化\citing{10.1145/3620666.3651323}，内存压缩技术的性能开销显著降低。结合现代应用程序数据普遍具有较高的压缩潜力，实时压缩冷数据来扩展有效内存容量成为可行方案。谷歌\citing{10.1145/3297858.3304053}在生产环境中率先将压缩内存作为交换后端，通过改进的冷热页面识别算法和工作集估计方法，使数据中心的内存利用率得到了提升。

这些解决方案的共同特点是采用了透明卸载策略，通过在内核层面优化swap子系统，使得应用程序无需修改即可从中受益。这种对应用透明的特性大大降低了技术落地的门槛，为解决内存资源紧张问题提供了切实可行的方案。

\subsection{工作集估计算法研究历史与现状}

工作集大小(Working Set Size, WSS)是量化进程内存需求的关键指标，它反映了进程在特定时间窗口内频繁访问的内存页面集合。传统Linux系统主要基于页表引用(Referenced)标志来估算WSS：通过统计被CPU访问而置位的页面数量来评估活跃内存使用量。然而，这种方法需要遍历整个页表，在处理大内存进程时会产生显著的性能开销，同时可能影响系统的整体响应性。

针对传统方法的局限性，研究者提出了多种优化方案。在虚拟化环境中，内存工作集的准确估算对于资源调度尤为重要。Vlad Nitu等人\citing{10.1145/3179422,10.1145/1165389.945462}创新性地将统计采样引入工作集估算。他们通过在Guest OS中部署气球驱动(balloon driver)，选择性地使部分页面映射失效并监控重新访问行为，从而在降低扫描开销的同时获得较准确的工作集估计。基于这一思路，Anna Melekhova等人\citing{Melekhova2015EstimatingWS}对气球驱动机制进行了改进，通过VirtIO接口实现了更高效的内存使用统计收集，使得工作集估算的准确度提升。

随着数据中心规模的扩大和负载特征的日益复杂化，基于历史数据的预测方法开始受到关注。Xie等人\citing{9076292}通过分析内存使用模式的周期性特征，提出了结合ARIMA和三指数平滑的混合预测模型。该模型能够捕捉内存使用的长期趋势和短期波动，与传统方法相比，这种基于预测的方法能够提前预知工作集大小的变化，为内存资源的动态调度提供了可能。

为进一步降低监控开销，Lian等人\citing{9860164}提出了基于eBPF的轻量级工作集估计方法。通过利用eBPF技术的高效事件追踪能力，他们实现了对缺页中断、内存分配和页面访问等关键事件的非侵入式监控。结合LightGBM机器学习模型，降低算法开销，便于部署。

近年来，深度学习等先进机器学习方法在工作集估算领域展现出良好的应用前景。多项研究\citing{10.1145/3297858.3304053,9870561,10.1155/2023/5959223}探索了针对特定应用场景的深度学习模型，通过建立更复杂的特征工程和预测模型来提高估算精度。这些方法虽然在特定场景下表现优异，但其泛化能力和部署成本仍需要进一步验证。


\section{本文的主要贡献与创新}

通过对现有异构后端透明装卸技术和工作集估计算法的分析，我们发现当前研究主要存在以下局限：首先，现有工作集估计算法往往针对特定的后端设备或应用场景进行优化，其适用范围受限；其次，基于统计采样或机器学习的方法需要针对不同场景重新调整参数或训练模型，迁移成本较高；最后，这些方法未能建立内存工作集与应用性能之间的直接关联，难以准确反映实际的内存需求。

随着异构后端的引入，存储后端的访问延迟显著降低，带宽大幅提升。在这种情况下，传统倾向于优先回收文件页面的策略不再合适。因为对于文件密集型应用而言，频繁访问的文件页面如果被回收，即使有高性能的存储后端，仍然会引入不必要的I/O开销，影响应用性能。因此，需要重新设计页面回收策略，在文件页面和匿名页面之间取得更好的平衡。

本文提出了一种基于内存压力感知的工作集估计框架。该框架通过协调内核态和用户态的配合，实现了对容器工作集大小的精确估计。具体创新点体现在以下两个方面：

\begin{itemize}
    \item 设计了一种基于内存压力的工作集估计框架。该框架将内存压力定义为内存资源短缺导致的应用性能衰退程度，通过在内核态收集和量化性能衰退指标，结合用户态的工作集计算模块，动态调整cgroup内存限制阈值，从而准确估算容器的实际内存需求。这种框架设计不依赖于特定的后端设备特征或应用类型，具有良好的通用性。
    
    \item 提出了一种新的页面访问距离计算方法。该方法能够根据实际的性能影响动态调整文件页面和匿名页面的回收比例，更好地适应现代存储设备的特性，从而提升系统整体性能，尤其是文件密集型应用的性能。
\end{itemize}

\section{本论文的结构安排}
本文的章节结构安排如下：

\footnote{脚注序号“\ding{172}，……，\ding{180}”的字体是“正文”，不是“上标”，序号与脚注内容文字之间空1个半角字符，脚注的段落格式为：单倍行距，段前空0磅，段后空0磅，悬挂缩进1.5字符；中文用宋体，字号为小五号，英文和数字用Times New Roman字体，字号为9磅；中英文混排时，所有标点符号（例如逗号“，”、括号“（）”等）一律使用中文输入状态下的标点符号，但小数点采用英文状态下的样式“.”。}