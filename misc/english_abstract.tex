\begin{englishabstract}

In recent years, data intensive workloads such as machine learning, graph processing, and in memory databases together with the virtualization overhead introduced by  containerized deployments have jointly driven demand for large capacity, high bandwidth memory; however, traditional DRAM, limited by physical scaling barriers and market volatility, has experienced a slowed decline in per bit cost and an overall cost increase, while real world applications frequently underutilize allocated memory, leaving a considerable number of cold pages. To address this tension, industry and academia have proposed diversified alternatives: at the media layer, solid state drives based on the Non Volatile Memory Express protocol (NVMe SSD) and non volatile memory (NVM) provide highdensity, low cost storage; at the interconnect layer, Compute Express Link (CXL) and Remote Direct Memory Access (RDMA) based remote memory extend bandwidth and access elasticity; at the software layer, memory compression techniques further relieve capacity pressure. Leveraging these technologies, proactively offloading cold pages to heterogeneous backends has become an effective cost optimization strategy; by incorporating heterogeneous backends into the Linux memory reclamation subsystem, cold data can be migrated continuously while remaining transparent to applications. Nevertheless, the current Linux memory manager still suffers from two major limitations: its reclamation logic prefers file backed pages, which can impair the performance of file intensive workloads, and its passive, pressure driven design only triggers under memory stress, making it difficult to fully exploit high performance heterogeneous backends for ongoing proactive cold page offloading.

To overcome these limitations, this study proposes a cold page adaptive proactive offloading scheme targeting heterogeneous back ends, focusing on two primary issues: (i) determining an appropriate offloading scale for different back ends, and (ii) accurately identifying hot and cold pages within the system. The core contributions are as follows:

\begin{itemize}
\item A memory pressure aware adaptive proactive offloading mechanism that \\autonomously decides the offloading scale for various heterogeneous back ends. Using synchronous reclamation latency as the pressure metric, the mechanism adapts the offloading volume across diverse workloads and, by integrating with the Linux Control Group (CGroup) framework, precisely regulates application memory offloading.
\item A reuse distance based hot/cold page identification algorithm. To address the tendency of existing algorithms to reclaim file backed pages detrimental to file intensive workloads the algorithm leverages page reuse distance (the number of pages accessed between two consecutive accesses to the same page) to more accurately identify hot file pages, thereby improving the performance of file dominant applications.
\end{itemize}

A prototype system has been implemented and experimentally evaluated in containerized deployment scenarios. Results show that the system effectively calibrates the offloading scale across different heterogeneous storage architectures and, compared with the baseline, reduces in container memory usage by 5\%\textasciitilde{}14\% while preserving service performance.


\englishkeyword{Tiered Memory, Reuse Distance, Hot-Cold Page Identification}

\end{englishabstract}


