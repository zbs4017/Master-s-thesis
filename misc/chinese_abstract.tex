	
\begin{chineseabstract}

近年来，机器学习、图计算和云计算等数据密集型应用的快速发展，对系统内存容量提出了前所未有的需求，容器化部署带来的虚拟化开销进一步加剧了这一需求。然而，传统DRAM技术正面临物理缩放限制和市场价格波动等挑战，内存成本持续上升。与此同时，新型存储与互连技术正在快速发展。NVMe SSD、新型非易失性存储器（Non-Volatile Memory, NVM）、计算快速链接（Compute Express Link, CXL）设备，以及基于RDMA的远程内存访问技术，为内存系统架构提供了新的可能性。此外，基于软件实现的内存压缩技术也在不断演进。这些新兴技术能够提供比DRAM更高的存储容量，同时显著降低单位容量的成本与功耗。

在此背景下，通过内核换入换出的分层内存进行透明卸载可以有效实现异构后端，降低内存成本。配合内核中的控制组（Control Group, CGroup）技术与换页机制协同工作，为实现内存资源的动态卸载提供了技术支撑。通过容器化部署和实时计算应用的工作集大小（Working Set Size，WSS），能够有效优化内存使用效率。

然而，该架构仍面临关键技术挑战：首先，冷热页面的精确识别直接影响内存卸载效率，不当的页面回收策略可能引发频繁页交换，导致性能回退；其次，工作集的动态计算与适配存在显著困难，不同应用场景呈现多样化的内存访问模式，而异构存储设备的性能特征差异显著，这为构建普适性的自适应工作集计算模型带来了挑战。

针对这些问题，本文的主要工作内容和创新点如下:
\begin{itemize}
    \item 本研究提出了一种基于内核态-用户态协同的自适应工作集估计算法。内核态实时监测内存回收延迟，量化内存压力并通过标准接口暴露；用户态基于压力数据动态计算工作集大小，结合cgroup机制约束容器内存使用。
    \item 提出了一种基于访问距离的文件热页识别算法。针对现有页面冷热识别算法倾向于回收文件页、对文件密集型应用不友好的问题，本方法基于页面访问距离，能够更准确地识别文件热页，从而提升文件密集型应用的性能。
\end{itemize}

本研究开发了相应的原型系统，并针对容器化Web应用场景进行了实验验证。实验结果表明，该系统能够有效识别不同异构后端存储架构下的容器工作集，在确保服务性能的同时，实现容器内存使用量5\%-14\%的显著降低。

\chinesekeyword{分层内存，工作集大小，内存管理，冷热页面识别}
\end{chineseabstract}